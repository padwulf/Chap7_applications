{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used ncon package\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "from timeit import default_timer as timer\n",
    "from experimentalsetup import final_pooling_evaluation\n",
    "from experimentalsetup import AUPRC, AUROC\n",
    "from experimentalsetup import read_tensor, read_testfilter, read_removetestlabels, read_trainfilter, read_removetrainlabels\n",
    "from experimentalsetup import K_effects_A, K_drugs_A, evaluate_grid_A\n",
    "from experimentalsetup import K_effects_B, K_drugs_B, evaluate_grid_B\n",
    "from experimentalsetup import K_effects_C, K_drugs_C, evaluate_grid_C\n",
    "from experimentalsetup import K_effects_T1, K_drugs_T1, evaluate_grid_T1\n",
    "from experimentalsetup import hdv_drugs_A, hdv_effects_A\n",
    "from experimentalsetup import hdv_effects_T1, hdv_effects_T1_help\n",
    "from experimentalsetup import hdv_effects_B, hdv_effects_B_help\n",
    "from experimentalsetup import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = read_tensor(\"Data_Indexed/triples_indexed\", (645, 645, 963))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((645, 645, 963), numpy.bool_)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape, type(Y[1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  SETTING A: new triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Definitions and hdv vector loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "dirname = 'Results/SettingA_'+str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdv_drugs = hdv_drugs_A(dirname)\n",
    "hdv_effects_a, hdv_effects_b = hdv_effects_A(Y, dirname)\n",
    "hdv_effects_a+=1\n",
    "hdv_effects_b+=1\n",
    "hdv_drugs+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Training and saving the models \n",
    "For cross-validation, we make use of the simple structure of HDC model that is a simple sum. During training, for each test set, we bundle the data into a model M. When predicting, we construct a model that bundles all models M, and subtract the specific bundel of the test set we want to predict for. In this way, repetitive bundling of the same data can be avoided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testfiler triple\n",
      "time for one exp:  134.32935448100034\n",
      "testfiler triple\n",
      "time for one exp:  136.56229307399917\n",
      "testfiler triple\n",
      "time for one exp:  130.5436303639981\n",
      "testfiler triple\n",
      "time for one exp:  129.44243205999737\n",
      "testfiler triple\n",
      "time for one exp:  128.12178352900082\n",
      "testfiler triple\n",
      "time for one exp:  122.56653087099767\n",
      "testfiler triple\n",
      "time for one exp:  123.28607773200201\n",
      "testfiler triple\n",
      "time for one exp:  123.23185858500437\n",
      "testfiler triple\n",
      "time for one exp:  120.38442323899653\n",
      "testfiler triple\n",
      "time for one exp:  122.17843013300444\n"
     ]
    }
   ],
   "source": [
    "for experimentnumber in range(n_splits):\n",
    "    if experimentnumber < 5:\n",
    "        hdv_effects = hdv_effects_a\n",
    "    else:\n",
    "        hdv_effects = hdv_effects_b\n",
    "\n",
    "    canceltrain = read_removetrainlabels(dirname+'/test_'+str(experimentnumber),Y.shape).astype(bool)\n",
    "    d1, d2, s = np.where(Y*canceltrain)\n",
    "\n",
    "    Mpos = np.zeros(hdv_drugs.shape[1])\n",
    "    beginexp = timer()\n",
    "    size = len(d1) #100000 #\n",
    "    for i in range(size): \n",
    "        Mpos+= (  hdv_drugs[d1[i],:] * hdv_drugs[d2[i],:] * hdv_effects[s[i],:] )\n",
    "    Mneg = np.zeros(hdv_drugs.shape[1])\n",
    "    size_ = 1*size\n",
    "    d1, d2, s = np.random.choice(Y.shape[0],size_), np.random.choice(Y.shape[1],size_), np.random.choice(Y.shape[2],size_)\n",
    "    for i in range(size_):\n",
    "        Mneg+= (  hdv_drugs[d1[i],:] * hdv_drugs[d2[i],:] * hdv_effects[s[i],:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    np.savetxt(dirname+\"/HDVresults/M_pos_\"+str(experimentnumber), Mpos)\n",
    "    np.savetxt(dirname+\"/HDVresults/M_neg_\"+str(experimentnumber), Mneg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Pooled prediction and save\n",
    "See note about cross-validation of earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for one exp:  1196.275055170001\n",
      "time for one exp:  1182.0016324880053\n",
      "time for one exp:  1198.6700161619956\n",
      "time for one exp:  1204.0287174240002\n",
      "time for one exp:  1185.6343844079965\n",
      "time for one exp:  1198.3154424000022\n",
      "time for one exp:  1202.6645389199984\n",
      "time for one exp:  1205.3333052029993\n",
      "time for one exp:  1211.0054911800034\n",
      "time for one exp:  1213.145319586998\n",
      "evaluaton (645, 645, 963) (645, 645, 963)\n",
      "0.7676971779626663 0.731201277928467\n"
     ]
    }
   ],
   "source": [
    "models_pos = np.array([np.loadtxt(dirname+\"/HDVresults/M_pos_\"+str(experimentnumber)) for experimentnumber in range(n_splits)])\n",
    "models = models_pos\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for experimentnumber in range(n_splits):\n",
    "    if experimentnumber < 5:\n",
    "        hdv_effects = hdv_effects_a\n",
    "    else:\n",
    "        hdv_effects = hdv_effects_b\n",
    "    test = np.array(pd.read_csv(dirname+'/test_'+str(experimentnumber), ' ',header=None))\n",
    "    M = np.sum(models, axis=0) - models[experimentnumber,:] \n",
    "\n",
    "    beginexp = timer()\n",
    "    size= len(test) #200000 #\n",
    "    for i in range(size):\n",
    "        predictions[test[i,0], test[i,1], test[i,2]] = np.sum(M * hdv_drugs[test[i,0],:] * hdv_drugs[test[i,1],:] * hdv_effects[test[i,2],:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))\n",
    "#np.savetxt(dirname+\"/HDVresults/res_pos\", [np.nanmean(AUROC_dd), np.nanmean(AUROC_e)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for one exp:  1222.9988489769967\n",
      "time for one exp:  1215.4451153519985\n",
      "time for one exp:  1215.7975618000055\n",
      "time for one exp:  1211.137882656003\n",
      "time for one exp:  1190.9218416489966\n",
      "time for one exp:  1190.7603842190001\n",
      "time for one exp:  1206.5388407100036\n",
      "time for one exp:  1199.5928634890006\n",
      "time for one exp:  1200.1088273939968\n",
      "time for one exp:  1191.8588472509946\n",
      "evaluaton (645, 645, 963) (645, 645, 963)\n",
      "0.8226324223877683 0.796500391695285\n"
     ]
    }
   ],
   "source": [
    "models_pos = np.array([np.loadtxt(dirname+\"/HDVresults/M_pos_\"+str(experimentnumber)) for experimentnumber in range(n_splits)])\n",
    "models_neg = np.array([np.loadtxt(dirname+\"/HDVresults/M_neg_\"+str(experimentnumber)) for experimentnumber in range(n_splits)])\n",
    "models = models_pos - models_neg\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for experimentnumber in range(n_splits):\n",
    "    if experimentnumber < 5:\n",
    "        hdv_effects = hdv_effects_a\n",
    "    else:\n",
    "        hdv_effects = hdv_effects_b\n",
    "    test = np.array(pd.read_csv(dirname+'/test_'+str(experimentnumber), ' ',header=None))\n",
    "    M = np.sum(models, axis=0) - models[experimentnumber,:] \n",
    "\n",
    "    beginexp = timer()\n",
    "    size= len(test) #200000 #\n",
    "    for i in range(size):\n",
    "        predictions[test[i,0], test[i,1], test[i,2]] = np.sum(M * hdv_drugs[test[i,0],:] * hdv_drugs[test[i,1],:] * hdv_effects[test[i,2],:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))\n",
    "np.savetxt(dirname+\"/HDVresults/res_func\", [np.nanmean(AUROC_dd), np.nanmean(AUROC_e)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setting T1: new drug-drug pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "dirname = 'Results/SettingT1_'+str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdv_drugs = hdv_drugs_A('Results/SettingA_'+str(0))\n",
    "hdv_drugs+=1\n",
    "hdv_effects_ = hdv_effects_T1(Y, dirname, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testfiler pair\n",
      "time for one exp:  33.18774786299764\n",
      "testfiler pair\n",
      "time for one exp:  32.569002533004095\n",
      "testfiler pair\n",
      "time for one exp:  32.417143038001086\n",
      "testfiler pair\n",
      "time for one exp:  32.90326153799833\n",
      "testfiler pair\n",
      "time for one exp:  32.62865646699356\n",
      "testfiler pair\n",
      "time for one exp:  32.61964438299765\n",
      "testfiler pair\n",
      "time for one exp:  33.86197010699834\n",
      "testfiler pair\n",
      "time for one exp:  32.96563966199756\n",
      "testfiler pair\n",
      "time for one exp:  32.23614525599987\n",
      "testfiler pair\n",
      "time for one exp:  32.8676972309986\n"
     ]
    }
   ],
   "source": [
    "for experimentnumber in range(n_splits):\n",
    "    hdv_effects = np.sign(np.sum(hdv_effects_,axis=0) - hdv_effects_[experimentnumber,:]) # do not use the representations calculated based on the test set\n",
    "    hdv_effects+=1\n",
    "\n",
    "    canceltrain = read_removetrainlabels(dirname+'/test_'+str(experimentnumber),Y.shape).astype(bool)\n",
    "    d1, d2, s = np.where(Y*canceltrain)\n",
    "\n",
    "    Mpos = np.zeros(hdv_drugs.shape[1])\n",
    "    beginexp = timer()\n",
    "    size =  len(d1) #100000 #\n",
    "    for i in range(size): \n",
    "        Mpos+= (  hdv_drugs[d1[i],:] * hdv_drugs[d2[i],:] * hdv_effects[s[i],:] )\n",
    "    Mneg = np.zeros(hdv_drugs.shape[1])\n",
    "    size_ = 1*size\n",
    "    d1, d2, s = np.random.choice(Y.shape[0],size_), np.random.choice(Y.shape[1],size_), np.random.choice(Y.shape[2],size_)\n",
    "    for i in range(size_):\n",
    "        Mneg+= (  hdv_drugs[d1[i],:] * hdv_drugs[d2[i],:] * hdv_effects[s[i],:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    np.savetxt(dirname+\"/HDVresults/M_pos_\"+str(experimentnumber), Mpos)\n",
    "    np.savetxt(dirname+\"/HDVresults/M_neg_\"+str(experimentnumber), Mneg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for one exp:  286.31510815300135\n",
      "time for one exp:  291.71816131800006\n",
      "time for one exp:  295.55100812300225\n",
      "time for one exp:  300.63555029700365\n",
      "time for one exp:  299.1008428159985\n",
      "time for one exp:  296.6020845890016\n",
      "time for one exp:  300.69272035599715\n",
      "time for one exp:  300.02548849600134\n",
      "time for one exp:  286.4545087449951\n",
      "time for one exp:  289.1186230309977\n",
      "evaluaton (645, 645, 963) (645, 645, 963)\n",
      "0.7719137937841952 0.7609546338887656\n"
     ]
    }
   ],
   "source": [
    "models_pos = np.array([np.loadtxt(dirname+\"/HDVresults/M_pos_\"+str(experimentnumber)) for experimentnumber in range(n_splits)])\n",
    "models = models_pos\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for experimentnumber in range(n_splits):\n",
    "    hdv_effects = np.sign(np.sum(hdv_effects_,axis=0) - hdv_effects_[experimentnumber,:]) # do not use the representations calculated based on the test set\n",
    "    hdv_effects+=1\n",
    "    \n",
    "    test = np.array(pd.read_csv(dirname+'/test_'+str(experimentnumber), ' ',header=None))\n",
    "    M = np.sum(models, axis=0) - models[experimentnumber,:] \n",
    "\n",
    "    beginexp = timer()\n",
    "    size=len(test) #4000 #\n",
    "    for i in range(size):\n",
    "        res_ = M * hdv_drugs[test[i,0],:] * hdv_drugs[test[i,1],:]\n",
    "        for j in range(Y.shape[2]):\n",
    "            predictions[test[i,0], test[i,1], j] = np.sum(res_ * hdv_effects[j,:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))\n",
    "np.savetxt(dirname+\"/HDVresults/res_pos\", [np.nanmean(AUROC_dd), np.nanmean(AUROC_e)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluaton (645, 645, 963) (645, 645, 963)\n",
      "0.7722762751390467 0.7609546338887657\n"
     ]
    }
   ],
   "source": [
    "predictions[np.isnan(predictions)]=0\n",
    "predictions+= predictions.transpose(1,0,2)\n",
    "\n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for one exp:  306.06686567799625\n",
      "time for one exp:  296.13649689400336\n",
      "time for one exp:  294.58695849399373\n",
      "time for one exp:  297.79588452199823\n",
      "time for one exp:  298.13720209399617\n",
      "time for one exp:  298.7787527000037\n",
      "time for one exp:  296.4032350799971\n",
      "time for one exp:  298.6644265750001\n",
      "time for one exp:  289.08434378200036\n",
      "time for one exp:  287.5129440150049\n",
      "evaluaton (645, 645, 963) (645, 645, 963)\n",
      "0.8235109437717855 0.8078274347811651\n"
     ]
    }
   ],
   "source": [
    "models_pos = np.array([np.loadtxt(dirname+\"/HDVresults/M_pos_\"+str(experimentnumber)) for experimentnumber in range(n_splits)])\n",
    "models_neg = np.array([np.loadtxt(dirname+\"/HDVresults/M_neg_\"+str(experimentnumber)) for experimentnumber in range(n_splits)])\n",
    "models = models_pos - models_neg\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for experimentnumber in range(n_splits):\n",
    "    hdv_effects = np.sign(np.sum(hdv_effects_,axis=0) - hdv_effects_[experimentnumber,:]) # do not use the representations calculated based on the test set\n",
    "    hdv_effects+=1\n",
    "    \n",
    "    test = np.array(pd.read_csv(dirname+'/test_'+str(experimentnumber), ' ',header=None))\n",
    "    M = np.sum(models, axis=0) - models[experimentnumber,:] \n",
    "\n",
    "    beginexp = timer()\n",
    "    size=len(test) #4000 #\n",
    "    for i in range(size):\n",
    "        res_ = M * hdv_drugs[test[i,0],:] * hdv_drugs[test[i,1],:]\n",
    "        for j in range(Y.shape[2]):\n",
    "            predictions[test[i,0], test[i,1], j] = np.sum(res_ * hdv_effects[j,:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))\n",
    "np.savetxt(dirname+\"/HDVresults/res_func\", [np.nanmean(AUROC_dd), np.nanmean(AUROC_e)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluaton (645, 645, 963) (645, 645, 963)\n",
      "0.8237916111596013 0.807827434781165\n"
     ]
    }
   ],
   "source": [
    "predictions[np.isnan(predictions)]=0\n",
    "predictions+= predictions.transpose(1,0,2)\n",
    "\n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SETTING B = (False, True, True): new drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testdrugs_(i,n_drugs, n_splits):\n",
    "    dx = int(n_drugs/n_splits+0.5)\n",
    "    a,b = i*dx , min((i+1)*dx, n_drugs)\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "dirname = 'Results/SettingB_'+str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdv_drugs = hdv_drugs_A('Results/SettingA_'+str(0))\n",
    "hdv_drugs+=1\n",
    "hdv_effects_ = hdv_effects_B(Y, dirname, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split1 in range(n_splits):\n",
    "    testdrugs1 = np.arange(testdrugs_(split1,len(Y), n_splits)[0],testdrugs_(split1,len(Y),n_splits)[1])\n",
    "    for split2 in range(n_splits):\n",
    "        trainfolds1 = np.delete(np.array(range(n_splits)), split1)\n",
    "        trainfolds2 = np.delete(np.array(range(n_splits)), split2)\n",
    "        hdv_effects = np.sign(np.sum(hdv_effects_[trainfolds1,:,:,:][:,trainfolds1,:,:], axis=(0,1))).astype('float64')\n",
    "        hdv_effects+=1\n",
    "        \n",
    "        testdrugs2 = np.arange(testdrugs_(split2,len(Y), n_splits)[0],testdrugs_(split2,len(Y),n_splits)[1])        \n",
    "        Ytest = np.full(Y.shape, False)\n",
    "        Ytest[testdrugs1[0]:testdrugs1[-1]+1, testdrugs2[0]:testdrugs2[-1]+1,:] = Y[testdrugs1[0]:testdrugs1[-1]+1, testdrugs2[0]:testdrugs2[-1]+1,:]\n",
    "        \n",
    "        d1, d2, s = np.where(Ytest)\n",
    "\n",
    "        \n",
    "        Mpos = np.zeros(hdv_drugs.shape[1])\n",
    "        beginexp = timer()\n",
    "        size =  len(d1) #100000 #\n",
    "        for i in range(size): \n",
    "            Mpos+= (  hdv_drugs[d1[i],:] * hdv_drugs[d2[i],:] * hdv_effects[s[i],:] )\n",
    "        Mneg = np.zeros(hdv_drugs.shape[1])\n",
    "        size_ = 1*size\n",
    "        d1, d2, s = np.random.choice(Y.shape[0],size_), np.random.choice(Y.shape[1],size_), np.random.choice(Y.shape[2],size_)\n",
    "        for i in range(size_):\n",
    "            Mneg+= (  hdv_drugs[d1[i],:] * hdv_drugs[d2[i],:] * hdv_effects[s[i],:] )\n",
    "        endexp = timer()\n",
    "        print(\"time for one exp: \" , (endexp-beginexp))\n",
    "        np.savetxt(dirname+\"/HDVresults/M_pos_\"+str(split1)+\"_\"+str(split2), Mpos)\n",
    "        np.savetxt(dirname+\"/HDVresults/M_neg_\"+str(split1)+\"_\"+str(split2), Mneg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pos = np.array([[np.loadtxt(dirname+\"/HDVresults/M_pos_\"+str(split1)+\"_\"+str(split2)) for split1 in range(n_splits)] for split2 in range(n_splits)])\n",
    "models = models_pos\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for split in range(n_splits):\n",
    "    testdrugs = np.arange(testdrugs_(split,len(Y), n_splits)[0],testdrugs_(split,len(Y),n_splits)[1])\n",
    "    traindrugs = np.delete(np.array(range(645)),testdrugs)\n",
    "    trainfolds = np.delete(np.array(range(n_splits)), split1)\n",
    "    hdv_effects = np.sign(np.sum(hdv_effects_[trainfolds,:,:,:][:,trainfolds,:,:], axis=(0,1))).astype('float64')\n",
    "    hdv_effects+=1\n",
    "        \n",
    "    M = np.sum(models[trainfolds,:,:][:,trainfolds,:], axis=(0,1))\n",
    "\n",
    "    beginexp = timer()\n",
    "    for i in testdrugs:\n",
    "        res_ = M * hdv_drugs[i,:]\n",
    "        for j in traindrugs:\n",
    "            res__ = res_ * hdv_drugs[j,:]\n",
    "            for k in range(Y.shape[2]):\n",
    "                predictions[i,j,k] = np.sum(res__ * hdv_effects[k,:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "    \n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))\n",
    "np.savetxt(dirname+\"/HDVresults/res_pos\", [np.nanmean(AUROC_dd), np.nanmean(AUROC_e)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pos = np.array([[np.loadtxt(dirname+\"/HDVresults/M_pos_\"+str(split1)+\"_\"+str(split2)) for split1 in range(n_splits)] for split2 in range(n_splits)])\n",
    "models_neg = np.array([[np.loadtxt(dirname+\"/HDVresults/M_neg_\"+str(split1)+\"_\"+str(split2)) for split1 in range(n_splits)] for split2 in range(n_splits)])\n",
    "models = models_pos - models_neg\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for split in range(n_splits):\n",
    "    testdrugs = np.arange(testdrugs_(split,len(Y), n_splits)[0],testdrugs_(split,len(Y),n_splits)[1])\n",
    "    traindrugs = np.delete(np.array(range(645)),testdrugs)\n",
    "    trainfolds = np.delete(np.array(range(n_splits)), split1)\n",
    "    hdv_effects = np.sign(np.sum(hdv_effects_[trainfolds,:,:,:][:,trainfolds,:,:], axis=(0,1))).astype('float64')\n",
    "    hdv_effects+=1\n",
    "        \n",
    "    M = np.sum(models[trainfolds,:,:][:,trainfolds,:], axis=(0,1))\n",
    "\n",
    "    beginexp = timer()\n",
    "    for i in testdrugs:\n",
    "        res_ = M * hdv_drugs[i,:]\n",
    "        for j in traindrugs:\n",
    "            res__ = res_ * hdv_drugs[j,:]\n",
    "            for k in range(Y.shape[2]):\n",
    "                predictions[i,j,k] = np.sum(res__ * hdv_effects[k,:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "    \n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))\n",
    "np.savetxt(dirname+\"/HDVresults/res_func\", [np.nanmean(AUROC_dd), np.nanmean(AUROC_e)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Setting C: two new drugs\n",
    "the features and training will be exactly the same as in setting B. Only the test set is different: where B's test set is made of the combinations of unseen drugs and seen drugs, C's test set is the combination of unseen drugs and unseen drugs. The train sets are in both cases the combinations of seen drugs and seen drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "dirname = 'Results/SettingC_'+str(0) # this will be used to save the evaluation accuracy\n",
    "dirname_B = 'Results/SettingB_'+str(0) #this will be used to load the features and the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdv_drugs = hdv_drugs_A('Results/SettingA_'+str(0))\n",
    "hdv_drugs+=1\n",
    "hdv_effects_ = hdv_effects_B(Y, dirname_B, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pos = np.array([[np.loadtxt(dirname_B+\"/HDVresults/M_pos_\"+str(split1)+\"_\"+str(split2)) for split1 in range(n_splits)] for split2 in range(n_splits)])\n",
    "models = models_pos\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for split in range(n_splits):\n",
    "    testdrugs = np.arange(testdrugs_(split,len(Y), n_splits)[0],testdrugs_(split,len(Y),n_splits)[1])\n",
    "    trainfolds = np.delete(np.array(range(n_splits)), split1)\n",
    "    hdv_effects = np.sign(np.sum(hdv_effects_[trainfolds,:,:,:][:,trainfolds,:,:], axis=(0,1))).astype('float64')\n",
    "    hdv_effects+=1\n",
    "        \n",
    "    M = np.sum(models[trainfolds,:,:][:,trainfolds,:], axis=(0,1))\n",
    "\n",
    "    beginexp = timer()\n",
    "    for i in testdrugs:\n",
    "        res_ = M * hdv_drugs[i,:]\n",
    "        for j in testdrugs:\n",
    "            res__ = res_ * hdv_drugs[j,:]\n",
    "            for k in range(Y.shape[2]):\n",
    "                predictions[i,j,k] = np.sum(res__ * hdv_effects[k,:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "    \n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))\n",
    "np.savetxt(dirname+\"/HDVresults/res_pos\", [np.nanmean(AUROC_dd), np.nanmean(AUROC_e)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pos = np.array([[np.loadtxt(dirname_B+\"/HDVresults/M_pos_\"+str(split1)+\"_\"+str(split2)) for split1 in range(n_splits)] for split2 in range(n_splits)])\n",
    "models_neg = np.array([[np.loadtxt(dirname_B+\"/HDVresults/M_neg_\"+str(split1)+\"_\"+str(split2)) for split1 in range(n_splits)] for split2 in range(n_splits)])\n",
    "models = models_pos - models_neg\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for split in range(n_splits):\n",
    "    testdrugs = np.arange(testdrugs_(split,len(Y), n_splits)[0],testdrugs_(split,len(Y),n_splits)[1])\n",
    "    trainfolds = np.delete(np.array(range(n_splits)), split)\n",
    "    hdv_effects = np.sign(np.sum(hdv_effects_[trainfolds,:,:,:][:,trainfolds,:,:], axis=(0,1))).astype('float64')\n",
    "    hdv_effects+=1\n",
    "        \n",
    "    M = np.sum(models[trainfolds,:,:][:,trainfolds,:], axis=(0,1))\n",
    "\n",
    "    beginexp = timer()\n",
    "    for i in testdrugs:\n",
    "        res_ = M * hdv_drugs[i,:]\n",
    "        for j in testdrugs:\n",
    "            res__ = res_ * hdv_drugs[j,:]\n",
    "            for k in range(Y.shape[2]):\n",
    "                predictions[i,j,k] = np.sum(res__ * hdv_effects[k,:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "    \n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))\n",
    "np.savetxt(dirname+\"/HDVresults/res_func\", [np.nanmean(AUROC_dd), np.nanmean(AUROC_e)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pos = np.array([np.loadtxt(dirname+\"/HDVresults/M_pos_\"+str(experimentnumber)) for experimentnumber in range(n_splits)])\n",
    "models = models_pos\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for split in range(n_splits):\n",
    "    testdrugs = np.arange(testdrugs_(split,len(Y), n_splits)[0],testdrugs_(split,len(Y),n_splits)[1])\n",
    "    trainfolds = np.delete(np.array(range(n_splits)), split1)\n",
    "    hdv_effects = np.sign(np.sum(hdv_effects_[trainfolds,:,:,:][:,trainfolds,:,:], axis=(0,1))).astype('float64')\n",
    "    hdv_effects+=1\n",
    "        \n",
    "    M = np.sum(models_pos[trainfolds,:,:][:,trainfolds,:], axis=(0,1))\n",
    "\n",
    "    test = np.array(pd.read_csv(dirname+'/test_'+str(experimentnumber), ' ',header=None))\n",
    "    M = np.sum(models, axis=0) - models[experimentnumber,:] \n",
    "\n",
    "    beginexp = timer()\n",
    "    size=2 #len(test) #\n",
    "    for i in testdrugs[:size]:\n",
    "        res_ = M * hdv_drugs[i,:] #* hdv_drugs[test[i,1],:]\n",
    "        for j in testdrugs:\n",
    "            res__ = res_ * hdv_drugs[j,:]\n",
    "            for k in range(Y.shape[2]):\n",
    "                predictions[i,j,k] = np.sum(res__ * hdv_effects[k,:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "    \n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))\n",
    "np.savetxt(dirname+\"/HDVresults/res_pos\", [np.nanmean(AUROC_dd), np.nanmean(AUROC_e)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pos = np.array([np.loadtxt(dirname+\"/HDVresults/M_pos_\"+str(experimentnumber)) for experimentnumber in range(n_splits)])\n",
    "models = models_pos\n",
    "\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for experimentnumber in range(n_splits):\n",
    "    if experimentnumber < 5:\n",
    "        hdv_effects = hdv_effects_a\n",
    "    else:\n",
    "        hdv_effects = hdv_effects_b\n",
    "    testdrugs = np.arange(testdrugs_(experimentnumber,len(Y), n_splits)[0],testdrugs_(experimentnumber,len(Y),n_splits)[1])\n",
    "    M = np.sum(models, axis=(0,1)) - np.sum(models,axis=0)[experimentnumber,:] - np.sum(models,axis=0)[experimentnumber,:] + models[experimentnumber,experimentnumber,:]\n",
    "\n",
    "    beginexp = timer()\n",
    "    size=2 #len(test) #\n",
    "    for i in testdrugs[:size]:\n",
    "        res_ = M * hdv_drugs[i,:] #* hdv_drugs[test[i,1],:]\n",
    "        for j in testdrugs:\n",
    "            res__ = res_ * hdv_drugs[j,:]\n",
    "            for k in range(Y.shape[2]):\n",
    "                predictions[i,j,k] = np.sum(res__ * hdv_effects[k,:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "np.save(dirname+\"/HDVresults/predictions_pos\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdv_drugs = hdv_drugs_A('Results/SettingA_'+str(0))\n",
    "hdv_effects_a, hdv_effects_b = hdv_effects_A(Y, 'Results/SettingA_'+str(0))\n",
    "hdv_effects_a+=1\n",
    "hdv_effects_b+=1\n",
    "hdv_drugs+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for one exp:  70.96228308100035\n",
      "time for one exp:  67.06033425100031\n",
      "time for one exp:  50.110947727000166\n",
      "time for one exp:  63.75925853800072\n",
      "time for one exp:  59.480018497000856\n",
      "time for one exp:  67.33223096399888\n",
      "time for one exp:  56.59757191999961\n",
      "time for one exp:  55.921421679999185\n",
      "time for one exp:  48.26102440700015\n",
      "time for one exp:  58.35788145600054\n"
     ]
    }
   ],
   "source": [
    "for experimentnumber in range(n_splits):\n",
    "    if experimentnumber < 5:\n",
    "        hdv_effects = hdv_effects_a\n",
    "    else:\n",
    "        hdv_effects = hdv_effects_b\n",
    "\n",
    "    testdrugs = np.arange(testdrugs_(experimentnumber,len(Y), n_splits)[0],testdrugs_(experimentnumber,len(Y),n_splits)[1])\n",
    "    Ytest = np.full(Y.shape, False)\n",
    "    Ytest[testdrugs, :, :]  = Y[testdrugs, :, :]\n",
    "    d1, d2, s = np.where(Ytest)\n",
    "\n",
    "    M = np.zeros(hdv_drugs.shape[1])\n",
    "    beginexp = timer()\n",
    "    size = len(d1) #100000 #\n",
    "    for i in range(size): \n",
    "        M+= (  hdv_drugs[d1[i],:] * hdv_drugs[d2[i],:] * hdv_effects[s[i],:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    np.savetxt(dirname+\"/HDVresults/M_unnormalized_\"+str(experimentnumber), M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for one exp:  47.89425516099982\n",
      "time for one exp:  43.01237861399932\n",
      "time for one exp:  42.88106956199954\n",
      "time for one exp:  41.70123533900005\n",
      "time for one exp:  42.11873250999997\n",
      "time for one exp:  43.8490694459997\n",
      "time for one exp:  43.62824070199895\n",
      "time for one exp:  44.018001324999204\n",
      "time for one exp:  44.58485619900057\n",
      "time for one exp:  43.30023003600036\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models_pos = np.array([np.loadtxt(dirname+\"/HDVresults/M_unnormalized_\"+str(experimentnumber)) for experimentnumber in range(n_splits)])\n",
    "models = models_pos\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for experimentnumber in range(n_splits):\n",
    "    if experimentnumber < 5:\n",
    "        hdv_effects = hdv_effects_a\n",
    "    else:\n",
    "        hdv_effects = hdv_effects_b\n",
    "    testdrugs = np.arange(testdrugs_(experimentnumber,len(Y), n_splits)[0],testdrugs_(experimentnumber,len(Y),n_splits)[1])\n",
    "    M = np.sum(models, axis=0) - models[experimentnumber,:] \n",
    "\n",
    "    beginexp = timer()\n",
    "    size=2 #len(test) #\n",
    "    for i in testdrugs[:size]:\n",
    "        res_ = M * hdv_drugs[i,:] #* hdv_drugs[test[i,1],:]\n",
    "        for j in range(Y.shape[1]):\n",
    "            res__ = res_ * hdv_drugs[j,:]\n",
    "            for k in range(Y.shape[2]):\n",
    "                predictions[i,j,k] = np.sum(res__ * hdv_effects[k,:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "np.save(dirname+\"/HDVresults/predictions_pos\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluaton (645, 645, 963) (645, 645, 963)\n",
      "0.7437180398466569 0.6300519288993759\n"
     ]
    }
   ],
   "source": [
    "predictions = np.load(dirname+\"/HDVresults/predictions_pos.npy\")\n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))\n",
    "np.savetxt(dirname+\"/HDVresults/res_pos\", [np.nanmean(AUROC_dd), np.nanmean(AUROC_e)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pos = np.array([np.loadtxt(dirname+\"/HDVresults/M_pos_\"+str(experimentnumber)) for experimentnumber in range(n_splits)])\n",
    "models_neg = np.array([np.loadtxt(dirname+\"/HDVresults/M_neg_\"+str(experimentnumber)) for experimentnumber in range(n_splits)])\n",
    "models = models_pos - models_neg\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for experimentnumber in range(n_splits):\n",
    "    if experimentnumber < 5:\n",
    "        hdv_effects = hdv_effects_a\n",
    "    else:\n",
    "        hdv_effects = hdv_effects_b\n",
    "    test = np.array(pd.read_csv(dirname+'/test_'+str(experimentnumber), ' ',header=None))\n",
    "    M = np.sum(models, axis=0) - models[experimentnumber,:] \n",
    "\n",
    "    beginexp = timer()\n",
    "    size=len(test) #100000 # \n",
    "    for i in range(size):\n",
    "        predictions[test[i,0], test[i,1], test[i,2]] = np.sum(M * hdv_drugs[test[i,0],:] * hdv_drugs[test[i,1],:] * hdv_effects[test[i,2],:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))\n",
    "np.savetxt(dirname+\"/HDVresults/res_func\", [np.nanmean(AUROC_dd), np.nanmean(AUROC_e)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SETTING C = (False, False, True): two new drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "dirname = 'Results/SettingC_'+str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdv_drugs = hdv_drugs_A('Results/SettingA_'+str(0))\n",
    "hdv_effects_a, hdv_effects_b = hdv_effects_A(Y, 'Results/SettingA_'+str(0))\n",
    "hdv_effects_a+=1\n",
    "hdv_effects_b+=1\n",
    "hdv_drugs+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for one exp:  7.463480355003412\n",
      "time for one exp:  6.9878928979997\n",
      "time for one exp:  5.5997927250027715\n",
      "time for one exp:  6.081257435002044\n",
      "time for one exp:  5.6753469030009\n",
      "time for one exp:  7.109685886000079\n",
      "time for one exp:  6.3300237500006915\n",
      "time for one exp:  6.150484365000011\n",
      "time for one exp:  5.404742991002422\n",
      "time for one exp:  6.119205925002461\n",
      "time for one exp:  6.789032870001392\n",
      "time for one exp:  5.899276070998894\n",
      "time for one exp:  4.69871392999994\n",
      "time for one exp:  5.778850953000074\n",
      "time for one exp:  5.495821954002167\n",
      "time for one exp:  7.452004907998344\n",
      "time for one exp:  6.41458115000205\n",
      "time for one exp:  6.324204717999237\n",
      "time for one exp:  5.259655500001827\n",
      "time for one exp:  6.2599810769970645\n",
      "time for one exp:  5.649337792001461\n",
      "time for one exp:  5.10864550900078\n",
      "time for one exp:  3.858914819000347\n",
      "time for one exp:  4.386332836998918\n",
      "time for one exp:  4.2059951559967885\n",
      "time for one exp:  5.591531512000074\n",
      "time for one exp:  4.492616890001955\n",
      "time for one exp:  4.371441362996848\n",
      "time for one exp:  3.6062902209996537\n",
      "time for one exp:  4.545636872000614\n",
      "time for one exp:  6.538193946998945\n",
      "time for one exp:  5.891126275000715\n",
      "time for one exp:  4.395863691999693\n",
      "time for one exp:  5.0375071199996455\n",
      "time for one exp:  5.006142805003037\n",
      "time for one exp:  6.391690592001396\n",
      "time for one exp:  5.258728854001674\n",
      "time for one exp:  5.173180534999119\n",
      "time for one exp:  4.2137768200009305\n",
      "time for one exp:  5.070718188999308\n",
      "time for one exp:  5.8467897070004256\n",
      "time for one exp:  5.529814121000527\n",
      "time for one exp:  4.102024320000055\n",
      "time for one exp:  4.614650454001094\n",
      "time for one exp:  4.2723117810019176\n",
      "time for one exp:  5.574413424998056\n",
      "time for one exp:  4.7703665619992535\n",
      "time for one exp:  5.278761737001332\n",
      "time for one exp:  4.222291221001797\n",
      "time for one exp:  5.326178125000297\n",
      "time for one exp:  7.850403918997472\n",
      "time for one exp:  7.2352316139986215\n",
      "time for one exp:  5.692900699999882\n",
      "time for one exp:  6.337754038999265\n",
      "time for one exp:  6.082785327998863\n",
      "time for one exp:  7.30498812299993\n",
      "time for one exp:  6.774266504999105\n",
      "time for one exp:  6.146675914998923\n",
      "time for one exp:  5.732654171999457\n",
      "time for one exp:  6.092726868999307\n",
      "time for one exp:  6.634523738001008\n",
      "time for one exp:  6.445951280998997\n",
      "time for one exp:  4.509628020001401\n",
      "time for one exp:  5.424883435000083\n",
      "time for one exp:  5.188037087002158\n",
      "time for one exp:  6.350503595000191\n",
      "time for one exp:  5.89959546099999\n",
      "time for one exp:  5.295517747003032\n",
      "time for one exp:  4.513556719000917\n",
      "time for one exp:  5.458304349001992\n",
      "time for one exp:  6.3642815839994\n",
      "time for one exp:  5.991224676999991\n",
      "time for one exp:  4.218118234999565\n",
      "time for one exp:  5.367664601999422\n",
      "time for one exp:  5.125974578000751\n",
      "time for one exp:  6.847825736997038\n",
      "time for one exp:  6.0473444429990195\n",
      "time for one exp:  4.987546450000082\n",
      "time for one exp:  4.224537492998934\n",
      "time for one exp:  5.2533986259986705\n",
      "time for one exp:  5.818338204000611\n",
      "time for one exp:  5.271628172999044\n",
      "time for one exp:  3.7180568090007\n",
      "time for one exp:  4.854016535002302\n",
      "time for one exp:  4.262173023002106\n",
      "time for one exp:  5.7408020820003\n",
      "time for one exp:  4.668141080001078\n",
      "time for one exp:  4.50330456699885\n",
      "time for one exp:  3.2900576569991244\n",
      "time for one exp:  4.6588019539995\n",
      "time for one exp:  6.838255541999388\n",
      "time for one exp:  6.21741101400039\n",
      "time for one exp:  4.595216795001761\n",
      "time for one exp:  5.434716884999943\n",
      "time for one exp:  5.022005971997714\n",
      "time for one exp:  6.3220892360004655\n",
      "time for one exp:  5.505444137001177\n",
      "time for one exp:  5.699154914000246\n",
      "time for one exp:  4.423210934997769\n",
      "time for one exp:  5.865719293997245\n"
     ]
    }
   ],
   "source": [
    "for experimentnumber in range(n_splits):\n",
    "    for experimentnumber_ in range(n_splits):\n",
    "        if experimentnumber < 5:\n",
    "            hdv_effects = hdv_effects_a\n",
    "        else:\n",
    "            hdv_effects = hdv_effects_b\n",
    "\n",
    "        testdrugs = np.arange(testdrugs_(experimentnumber,len(Y), n_splits)[0],testdrugs_(experimentnumber,len(Y),n_splits)[1])\n",
    "        testdrugs__ = np.arange(testdrugs_(experimentnumber_,len(Y), n_splits)[0],testdrugs_(experimentnumber_,len(Y),n_splits)[1])\n",
    "        \n",
    "        Ytest = np.full(Y.shape, False)\n",
    "        #Ytest[testdrugs, :,:][:,testdrugs__, :] = Y[testdrugs, :,:][:,testdrugs__, :]\n",
    "        Ytest[testdrugs[0]:testdrugs[-1]+1, testdrugs__[0]:testdrugs__[-1]+1,:] = Y[testdrugs[0]:testdrugs[-1]+1, testdrugs__[0]:testdrugs__[-1]+1,:]\n",
    "        \n",
    "        d1, d2, s = np.where(Ytest)\n",
    "\n",
    "        M = np.zeros(hdv_drugs.shape[1])\n",
    "        beginexp = timer()\n",
    "        size = len(d1) #100000 #\n",
    "        for i in range(size): \n",
    "            M+= (  hdv_drugs[d1[i],:] * hdv_drugs[d2[i],:] * hdv_effects[s[i],:] )\n",
    "        #size_ = 1*size\n",
    "        #d1, d2, s = np.random.choice(Y.shape[0],size_), np.random.choice(Y.shape[1],size_), np.random.choice(Y.shape[2],size_)\n",
    "        #for i in range(size_): \n",
    "        #    M-= (  hdv_drugs[d1[i],:] * hdv_drugs[d2[i],:] * hdv_effects[s[i],:] )\n",
    "        endexp = timer()\n",
    "        print(\"time for one exp: \" , (endexp-beginexp))\n",
    "        np.savetxt(dirname+\"/HDVresults/M_unnormalized_\"+str(experimentnumber)+\"_\"+str(experimentnumber_), M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for one exp:  4.014834584999335\n",
      "time for one exp:  3.9915483459990355\n",
      "time for one exp:  4.003380614001799\n",
      "time for one exp:  3.9843636190016696\n",
      "time for one exp:  4.017887336001877\n",
      "time for one exp:  4.044881303998409\n",
      "time for one exp:  4.052052523999009\n",
      "time for one exp:  4.323146897000697\n",
      "time for one exp:  4.047937997002009\n",
      "time for one exp:  3.7434131590016477\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models_pos = np.array([[np.loadtxt(dirname+\"/HDVresults/M_unnormalized_\"+str(experimentnumber)+\"_\"+str(experimentnumber_)) for experimentnumber in range(n_splits)] for experimentnumber_ in range(n_splits)])\n",
    "models = models_pos\n",
    "\n",
    "predictions = np.nan*np.ones(Y.shape)\n",
    "\n",
    "for experimentnumber in range(n_splits):\n",
    "    if experimentnumber < 5:\n",
    "        hdv_effects = hdv_effects_a\n",
    "    else:\n",
    "        hdv_effects = hdv_effects_b\n",
    "    testdrugs = np.arange(testdrugs_(experimentnumber,len(Y), n_splits)[0],testdrugs_(experimentnumber,len(Y),n_splits)[1])\n",
    "    M = np.sum(models, axis=(0,1)) - np.sum(models,axis=0)[experimentnumber,:] - np.sum(models,axis=0)[experimentnumber,:] + models[experimentnumber,experimentnumber,:]\n",
    "\n",
    "    beginexp = timer()\n",
    "    size=2 #len(test) #\n",
    "    for i in testdrugs[:size]:\n",
    "        res_ = M * hdv_drugs[i,:] #* hdv_drugs[test[i,1],:]\n",
    "        for j in testdrugs:\n",
    "            res__ = res_ * hdv_drugs[j,:]\n",
    "            for k in range(Y.shape[2]):\n",
    "                predictions[i,j,k] = np.sum(res__ * hdv_effects[k,:] )\n",
    "    endexp = timer()\n",
    "    print(\"time for one exp: \" , (endexp-beginexp))\n",
    "    \n",
    "np.save(dirname+\"/HDVresults/predictions_pos\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluaton (645, 645, 963) (645, 645, 963)\n",
      "0.7327513102305624 0.7019753795163216\n"
     ]
    }
   ],
   "source": [
    "predictions = np.load(dirname+\"/HDVresults/predictions_pos.npy\")\n",
    "AUROC_dd = evaluation(predictions, Y, AUROC, (False, False, True))\n",
    "AUROC_e = evaluation(predictions, Y, AUROC, (True, True, False))\n",
    "print(np.nanmean(AUROC_dd), np.nanmean(AUROC_e))\n",
    "np.savetxt(dirname+\"/HDVresults/res_pos\", [np.nanmean(AUROC_dd), np.nanmean(AUROC_e)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recalculate final predictions and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from threestep import NstepRegressor, KroneckerKernel\n",
    "from experimentalsetup import testdrugs_\n",
    "def final_pooling_prediction(Y,setting,dirname,n_splits,metric,scheme):\n",
    "    Yhat = np.zeros(Y.shape)\n",
    "    if setting == (False,True,True) or setting == (False,False,True): # in these settings there is not in every fold an estimation, so we cannot simply add predictions, non predicted must remain nan\n",
    "        Yhat[:] = np.nan\n",
    "    for experimentnumber in range(n_splits):\n",
    "        opi = str(scheme)+metric.__name__\n",
    "        optimizationresults = pd.read_csv(dirname+'/hypamoptimization_'+str(experimentnumber), sep='\\t')#, names=colnames)\n",
    "        o = list(optimizationresults[optimizationresults[opi] == max(optimizationresults[opi])].iloc[0,0:3])\n",
    "        nstep = NstepRegressor(o)\n",
    "        print(o)\n",
    "        if setting == (True, True, True) or setting == 'T1':\n",
    "\n",
    "            K1 = K2 =  np.loadtxt(dirname+\"/Kdrugs_rbf\")\n",
    "            K3 = np.loadtxt(dirname+\"/Keffects_cos_\"+str(experimentnumber))\n",
    "            K = KroneckerKernel([K1, K2, K3])\n",
    "\n",
    "            #load the matrices into Ktrain kroneckerkernel\n",
    "            canceltest = read_removetestlabels(dirname+'/test_'+str(experimentnumber),Y.shape)\n",
    "            canceltrain = read_removetrainlabels(dirname+'/test_'+str(experimentnumber),Y.shape)\n",
    "            Yest = nstep.fit_predict_LO(K,Y*canceltest, setting)\n",
    "            Yimputed = Y + (Yest-Y)*canceltrain #for the test data, Y is replaced by an estimation. This improves quality of training data\n",
    "            Yest = nstep.fit_predict_LO(K,Yimputed,setting)\n",
    "            Yhat = Yhat + Yest*canceltrain # put training estimations to zero and add these to the Yhat, if this is done for every fold, the Yhat tensor is a pooled estimation from the folds\n",
    "\n",
    "        if setting == (False, True, True):\n",
    "            testdrugs = np.arange(testdrugs_(experimentnumber,len(Y),n_splits)[0],testdrugs_(experimentnumber,len(Y), n_splits)[1])\n",
    "            Ytrain = np.delete(np.delete(Y, testdrugs, axis=0), testdrugs, axis=1)\n",
    "            Ytest = np.delete(Y, testdrugs, axis=1)[testdrugs[0]:testdrugs[-1], :,:]\n",
    "            K1 = K2 =  np.loadtxt(dirname+\"/Kdrugs_rbf\")\n",
    "            K3 = np.loadtxt(dirname+\"/Keffects_cos_\"+str(experimentnumber))\n",
    "            Ktrain = KroneckerKernel([np.delete(np.delete(K1, testdrugs, axis=0), testdrugs,axis=1), np.delete(np.delete(K2, testdrugs, axis=0), testdrugs,axis=1), K3])\n",
    "            Ktest = KroneckerKernel([np.delete(K1, testdrugs, axis=1)[testdrugs[0]:testdrugs[-1], :], np.delete(np.delete(K2, testdrugs, axis=0), testdrugs,axis=1), K3])\n",
    "            nstep.fit(Ktrain, Ytrain.astype('float64'))\n",
    "            Yest = nstep.predict(Ktest) #.astype('float32')\n",
    "            # assign the predictions correctly: note we did not, due to symmetry estimate for a diagonal block (these acutally coresspond to setting C = (False,False,True)). This is why there is a upper part assignment and lower part assignment (below the diagonal block)\n",
    "            print(Yhat.shape, Ytrain.shape, Ytest.shape, Yest.shape,len(testdrugs))\n",
    "\n",
    "            Yhat[testdrugs[0]:testdrugs[-1], :testdrugs[0] , :] = Yest[:,:testdrugs[0],:]\n",
    "            Yhat[testdrugs[0]:testdrugs[-1], testdrugs[-1]+1: , :] = Yest[:,testdrugs[0]:,:]\n",
    "\n",
    "        if setting == (False, False, True):\n",
    "            testdrugs = np.arange(testdrugs_(experimentnumber,len(Y),n_splits)[0],testdrugs_(experimentnumber,len(Y), n_splits)[1])\n",
    "            Ytrain = np.delete(np.delete(Y, testdrugs, axis=0), testdrugs, axis=1)\n",
    "            Ytest = Y[testdrugs[0]:testdrugs[-1], testdrugs[0]:testdrugs[-1],:]\n",
    "            K1 = K2 =  np.loadtxt(dirname+\"/Kdrugs_rbf\")\n",
    "            K3 = np.loadtxt(dirname+\"/Keffects_cos_\"+str(experimentnumber))\n",
    "            Ktrain = KroneckerKernel([np.delete(np.delete(K1, testdrugs, axis=0), testdrugs,axis=1), np.delete(np.delete(K2, testdrugs, axis=0), testdrugs,axis=1), K3])\n",
    "            Ktest = KroneckerKernel([np.delete(K1, testdrugs, axis=1)[testdrugs[0]:testdrugs[-1], :], np.delete(K2, testdrugs, axis=1)[testdrugs[0]:testdrugs[-1], :], K3])\n",
    "\n",
    "            nstep.fit(Ktrain, Ytrain.astype('float64'))\n",
    "            Yest = nstep.predict(Ktest) #.astype('float32')\n",
    "            # assign the predictions correctly: here we assign the diagonal blocks. Note that here we need to set the diagonal elements to nan to neglegt in the evaluation.\n",
    "            Yhat[testdrugs[0]:testdrugs[-1], testdrugs[0]:testdrugs[-1] , :] = Yest\n",
    "            ndiag = len(Yhat)\n",
    "            for i in range(ndiag):\n",
    "                Yhat[i,i,:] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        print(experimentnumber)\n",
    "    np.save('final_predictions_'+str(setting)+ metric.__name__+str(scheme),Yhat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "dirname = 'Results/SettingA_0'\n",
    "\n",
    "metrics = [AUROC, AUPRC]\n",
    "schemes = [(True, True, False), (False, False, True)]\n",
    "\n",
    "for metric in metrics:\n",
    "    for scheme in schemes:\n",
    "        final_pooling_prediction(Y,(True, True, True),dirname,n_splits,metric,scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "dirname = 'Results/SettingT1_0'\n",
    "\n",
    "metrics = [AUROC, AUPRC]\n",
    "schemes = [(True, True, False), (False, False, True)]\n",
    "\n",
    "for metric in metrics:\n",
    "    for scheme in schemes:\n",
    "        final_pooling_prediction(Y,'T1',dirname,n_splits,metric,scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "dirname = 'Results/SettingB_0'\n",
    "\n",
    "metrics = [AUROC, AUPRC]\n",
    "schemes = [(True, True, False), (False, False, True)]\n",
    "\n",
    "for metric in metrics:\n",
    "    for scheme in schemes:\n",
    "        final_pooling_prediction(Y,(False, True, True),dirname,n_splits,metric,scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "dirname = 'Results/SettingC_0'\n",
    "\n",
    "metrics = [AUROC, AUPRC]\n",
    "schemes = [(True, True, False), (False, False, True)]\n",
    "\n",
    "for metric in metrics:\n",
    "    for scheme in schemes:\n",
    "        final_pooling_prediction(Y,(False, False, True),dirname,n_splits,metric,scheme)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
